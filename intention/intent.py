# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'pyQts\desktop_assist.ui'
#
# Created by: PyQt5 UI code generator 5.15.0
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
import  cv2
import numpy as np
import argparse
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import datetime

class Ui_Assistance(object):

    def mess(self, title, message):
        mess = QtWidgets.QMessageBox()
        mess.setWindowTitle(title)
        mess.setText(message)
        mess.setStandardButtons(QtWidgets.QMessageBox.Ok)
        mess.exec_()

    
    def open_camera(self):
        model = Sequential()

        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))
        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))
        
        model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))
        
        model.add(Flatten())
        model.add(Dense(1024, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(7, activation='softmax'))
        
        
        model.load_weights('model.h5')
    # prevents openCL usage and unnecessary logging messages
        cv2.ocl.setUseOpenCL(False)
    # dictionary which assigns each label an emotion (alphabetical order)
        emotion_dict = {0: "Angry", 1: "Disgusted", 2: "Fearful", 3: "Happy", 4: "Neutral", 5: "Sad", 6: "Surprised"}
        
        # start the webcam feed
        cap = cv2.VideoCapture(0)
        emotions = []
        while True:
                # Find haar cascade to draw bounding box around face
            ret, frame = cap.read()
            if not ret:
                break
            facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)
        
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)
                roi_gray = gray[y:y + h, x:x + w]
                cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)
                prediction = model.predict(cropped_img)
                maxindex = int(np.argmax(prediction))
                #cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)
        
                emotions.append(emotion_dict[maxindex])
                
            cv2.imshow('Video', cv2.resize(frame,(1600,960),interpolation = cv2.INTER_CUBIC))
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        
        emotion = emotions[-1]
        
        if emotion == 'Fearful':
            self.mess("face", "looks fearful")
            
        elif emotion == 'Sad':
            self.mess("face", "Looks like you are sad")
            
        elif emotion == 'Angry':
            self.mess("face", "Anger is detected")
            
        elif emotion == 'Surprised':
            self.mess("face", "You look surprised")
            
        elif emotion == 'Disgusted':
            self.mess("face", "You look disgusted")
            
        elif emotion == 'Neutral':
            self.mess("face", "A neutral look")
            
        elif emotion == 'Happy':
            self.mess("face", "You look happy")
            
            

    
    def setupUi(self, Assistance):
        Assistance.setObjectName("Assistance")
        Assistance.resize(310, 310)
        self.btn_start = QtWidgets.QPushButton(Assistance)
        self.btn_start.setGeometry(QtCore.QRect(100, 120, 111, 61))
        font = QtGui.QFont()
        font.setFamily("Bauhaus 93")
        font.setPointSize(16)
        
        self.btn_start.setFont(font)
        self.btn_start.setObjectName("btn_start")
        self.btn_start.clicked.connect(self.open_camera)
        
        
        self.lblback = QtWidgets.QLabel(Assistance)
        self.lblback.setGeometry(QtCore.QRect(-4, 0, 601, 311))
        self.lblback.setText("")
        self.lblback.setObjectName("lblback")
        
        self.label = QtWidgets.QLabel(Assistance)
        self.label.setGeometry(QtCore.QRect(40, 90, 251, 20))
        self.label.setAlignment(QtCore.Qt.AlignCenter)
        self.label.setObjectName("label")
        self.label_2 = QtWidgets.QLabel(Assistance)
        self.label_2.setGeometry(QtCore.QRect(0, 290, 341, 21))
        font = QtGui.QFont()
        font.setFamily("Arial Narrow")
        font.setPointSize(10)
        font.setBold(False)
        font.setItalic(True)
        font.setWeight(50)
        self.label_2.setFont(font)
        self.label_2.setStyleSheet("background-color: rgb(255, 255, 255);")
        self.label_2.setObjectName("label_2")
       
        
        self.lblback.raise_()
        self.btn_start.raise_()

        self.retranslateUi(Assistance)
        QtCore.QMetaObject.connectSlotsByName(Assistance)

    def retranslateUi(self, Assistance):
        _translate = QtCore.QCoreApplication.translate
        Assistance.setWindowTitle(_translate("Assistance", "Expressions"))
        self.btn_start.setText(_translate("Assistance", "OPEN CAM"))
        self.label.setText(_translate("Assistance", "<html><head/><body><p align=\"center\">Click OPEN CAM to detect emotion from the webcam</p></body></html>"))
        self.label_2.setText(_translate("Assistance", "<html><head/><body><p align=\"center\"><span style=\" font-size:7pt; font-style:italic;\"> this software takes image from the webcam and reads the user\'s emotion........</span></p></body></html>"))
        


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    Assistance = QtWidgets.QDialog()
    ui = Ui_Assistance()
    ui.setupUi(Assistance)
    Assistance.show()
    sys.exit(app.exec_())
